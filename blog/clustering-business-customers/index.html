<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Clustering Business Users in R</title>
  <meta property="og:title" content="Clustering Business Users in R" />
  <meta name="twitter:title" content="Clustering Business Users in R" />
  <meta name="description" content="I often get questions like “How many profiles do Business customers have?” or “How often to Business cusotmers log in?”. These are useful questions to ask when designing and developing a product to fit the needs of a specific user segment, but a singular answer isn’t always sufficient.
You could answer these questions with a mean or median, but these can be misleading if the metric in question isn’t normally distributed.">
  <meta property="og:description" content="I often get questions like “How many profiles do Business customers have?” or “How often to Business cusotmers log in?”. These are useful questions to ask when designing and developing a product to fit the needs of a specific user segment, but a singular answer isn’t always sufficient.
You could answer these questions with a mean or median, but these can be misleading if the metric in question isn’t normally distributed.">
  <meta name="twitter:description" content="I often get questions like “How many profiles do Business customers have?” or “How often to Business cusotmers log in?”. These are useful questions to ask when designing and developing a product to …">
  <meta name="author" content="Julian Winternheimer"/>
  <link href='/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta property="og:image" content="/img/julian-avatar.png" />
  <meta name="twitter:image" content="/img/julian-avatar.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@julheimer" />
  <meta name="twitter:creator" content="@julheimer" />
  <meta property="og:url" content="/blog/clustering-business-customers/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Data Analysis?" />

  <meta name="generator" content="Hugo 0.23" />
  <link rel="canonical" href="/blog/clustering-business-customers/" />
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Data Analysis?">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/main.css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="/css/pygment_highlights.css" />
  <link rel="stylesheet" href="/css/highlight.min.css" />




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe.min.css" integrity="sha256-sCl5PUOGMLfFYctzDW3MtRib0ctyUvI9Qsmq2wXOeBY=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/default-skin/default-skin.min.css" integrity="sha256-BFeI1V+Vh1Rk37wswuOYn5lsTcaU96hGaI7OUVCLjPc=" crossorigin="anonymous" />



<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

</head>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Data Analysis?</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">Samples</a>
              <div class="navlinks-children">
                
                  <a href="/post/2017-03-07-bigimg-sample">Big Image Sample</a>
                
                  <a href="/post/2017-03-05-math-sample">Math Sample</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="About" href="/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        

        

        
      </ul>
    </div>

    <div class="avatar-container">
      <div class="avatar-img-border">
        
          <a title="Data Analysis?" href="/">
            <img class="avatar-img" src="/img/julian-avatar.png" alt="Data Analysis?" />
          </a>
        
      </div>
    </div>

  </div>
</nav>




    
  
  
  




  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              <h1>Clustering Business Users in R</h1>
                
                
                  <span class="post-meta">
  Posted on November 20, 2017
  
</span>


                
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <p>I often get questions like “How many profiles do Business customers have?” or “How often to Business cusotmers log in?”. These are useful questions to ask when designing and developing a product to fit the needs of a specific user segment, but a singular answer isn’t always sufficient.</p>
<p>You could answer these questions with a mean or median, but these can be misleading if the metric in question isn’t normally distributed. You could respond with density plots and CDFs and communicate characteristics of the distributions, but I’ve found that it’s slightly difficult to comminicate what these plots mean (CDFs in particular).</p>
<p>Another approach you could take is clustering users based on a given set of features. For Buffer, these features could be the number of profiles a user has, the number of team members a user has, and the median number of posts shared per week. This approach can be more intuitive to people that don’t regularly work with data, and fits well with the idea of different user personas.</p>
<p>There are many clustering techniques, most of which are not too computer intensive. These have proven immensely useful in helping analysts discern patterns in datasets with multiple features. We’ll go over three in this analysis: k-means clustering, hierarchical clustering, and partitioning around medoids (PAM).</p>
<div id="k-means-clustering" class="section level3">
<h3>K-means Clustering</h3>
<p>One of the oldest methods of cluster analysis is known as k-means cluster analysis. The first step (and certainly not a trivial one) when using k-means cluster analysis is to specify the number of clusters (k) that will be formed in the final solution.</p>
<p>The process begins by choosing k observations to serve as centers for the clusters. Then, the distance from each of the other observations is calculated for each of the k clusters, and observations are put in the cluster to which they are the closest. After each observation has been put in a cluster, the center of the clusters is recalculated, and every observation is checked to see if it might be closer to a different cluster, now that the centers have been recalculated. The process continues until no observations switch clusters.</p>
<div class="figure">
<img src="http://hi.buffer.com/1f070v173o20/Screen%20Shot%202017-11-20%20at%204.23.02%20PM.png" />

</div>
<p>K-means clustering is usually very fast, as you don’t need to calculate the distances between each data point and every other data point. A downside is that you are likely to get different results each time you reorder the data. The structure of a 3-cluster solution can be lost if you choose k = 4.</p>
</div>
<div id="partitioning-around-medoids-pam" class="section level3">
<h3>Partitioning around Medoids (PAM)</h3>
<p>The R <code>cluster</code> library provides a modern alternative to k-means clustering, known as <code>pam</code>. The term “medoid” refers to an observation within a cluster for which the sum of the distances between it and all the other members of the cluster is a minimum.</p>
<p><code>pam</code> requires that you know the number of clusters that you want (like k-means clustering), but it does more computation than k-means in order to insure that the medoids it finds are truly representative of the observations within a given cluster.</p>
<p>With pam, the sums of the distances between objects within a cluster are constantly recalculated as observations move around, which will hopefully provide a more reliable solution. Furthermore, as a by-product of the clustering operation it identifies the observations that represent the medoids, and these observations (one per cluster) can be considered a representative example of the members of that cluster which may be useful in some situations. As with k-means, there’s no guarantee that the structure that’s revealed with a small number of clusters will be retained when you increase the number of clusters.</p>
</div>
<div id="hierarchial-clustering" class="section level3">
<h3>Hierarchial Clustering</h3>
<p>Hierarchical agglomerative clustering methods, starts out by putting each observation into its own separate cluster. It then examines all the distances between all the observations and pairs together the two closest ones to form a new cluster. This is a simple operation, since hierarchical methods require a distance matrix, and it represents exactly what we want - the distances between individual observations.</p>
<p>There are different methods to form the new clusters, and we’ll use one that tries to minimize the distance between the observations in a single cluster.</p>
<p>Alright, let’s get on with clustering business customers.</p>
</div>
<div id="data-collection" class="section level3">
<h3>Data collection</h3>
<p>We’ll use the <code>buffer</code> package to query Redshift for every customer on the <code>business_v2_small_monthly</code> plan, the number of profiles they have, the number of team members they have, and the number of successful charges they have made. For simplicity’s sake, we’ll cluster Business customers only by the number of profiles and team members they have. In the future we can include many more features to cluster by.</p>
<pre class="sql"><code>select 
  s.customer as customer_id
  , u.user_id
  , count(distinct i.id) as paid_invoices
  , count(distinct p.id) as profiles
from stripe._subscriptions as s
inner join users as u
  on s.customer = u.billing_stripe_id
left join stripe._invoices as i
  on s.id = i.subscription_id
left join dbt.profiles as p
  on p.user_id = u.user_id
where s.plan_id = &#39;business_v2_small_monthly&#39;
  and i.paid
  and (p.is_deleted = false or p.is_deleted is null)
  and (p.is_disabled = false or p.is_disabled is null)
group by 1, 2</code></pre>
<p>The team members and organizations data is a little complex, so we’ll import it from Looker, where it is already modeled.</p>
<pre class="r"><code># get team member data
team_members &lt;- get_look(4196)

# rename columns
colnames(team_members) &lt;- c(&#39;user_id&#39;, &#39;team_members&#39;)

# set user_id as character
team_members$user_id &lt;- as.character(team_members$user_id)</code></pre>
<p>Now we can join the <code>customers</code> and <code>team_members</code> dataframes into a new one called <code>users</code>.</p>
<pre class="r"><code># join customers and team members
users &lt;- customers %&gt;% 
  left_join(team_members, by = &#39;user_id&#39;)</code></pre>
<p>The units of measurement are not the same for each variable, so we may want to scale the data. We want the unit of change in each coordinate to represent the same degree of difference.</p>
<pre class="r"><code># get the variables to user
features &lt;- users %&gt;% 
  select(profiles, team_members)

# get the scaled matrix
p_matrix &lt;- scale(features)

# get the mean values of the columns
p_center &lt;- attr(p_matrix, &quot;scaled:center&quot;)

# get the standard deviations
p_scale &lt;- attr(p_matrix, &quot;scaled:scale&quot;)</code></pre>
</div>
<div id="hierarchical-clustering" class="section level3">
<h3>Hierarchical clustering</h3>
<p>Now we can try the <code>hclust</code> method.</p>
<pre class="r"><code># create distance matrix
d &lt;- dist(p_matrix, method = &quot;euclidean&quot;)

# do the clustering
pfit &lt;- hclust(d, method = &quot;ward.D&quot;)</code></pre>
<p>Now we can plot the dendrogram with a given number of clusters. We’ll start out with 3. This is just an arbitrary guess made by looking at the dendrogram, but we will explore methods for choosing the number of clusters later on.</p>
<p><img src="/blog/clustering-business-customers_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We can use the <code>cutree()</code> function to extract the specific numbers from each cluster and assign them to our <code>users</code> dataset.</p>
<pre class="r"><code># get group numbers 
users$group &lt;- as.factor(cutree(pfit, k = 3))</code></pre>
<p>Now we can plot the number of profiles and team members for users in each cluster.</p>
<p><img src="/blog/clustering-business-customers_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>We can make a few quick observations from this scatterplot.</p>
<ul>
<li><p>The first cluster has a low number of profiles (7 or less) and 0 or 1 team member.</p></li>
<li><p>The second cluster has 2 or more team members and 15 or less profiles.</p></li>
<li><p>The third cluster has more profiles (from 8 to 25) and a uniformly distributed number of team members.</p></li>
</ul>
<p>This all begs the question of whether whether a given cluster represents actual structure in the data or is an artifact of the clustering algorithm. There are often clusters that represent structure in the data mixed with one or two clusters that represent the “other” data that doesn’t fit into any of the clusters. Clusters of “other” tend to be made up of data points that have no relationship to each other.</p>
<p>We eyeballed the appropriate k in this case from the dendrogram, but this isn’t always feasible with a large dataset. Can we pick a plausible k in a more automated fashion?</p>
</div>
<div id="finding-the-number-of-clusters-k" class="section level3">
<h3>Finding the number of clusters K</h3>
<p>There are a number of heuristics and rules-of-thumb for picking clusters; a given heu- ristic will work better on some datasets than others.</p>
<p><strong><em>Total within sum of squares</em></strong> One simple heuristic is to compute the total within sum of squares (WSS) for different values of k and look for an elbow in the curve. If we define the cluster’s centroid as the point that is the mean value of all the points in the cluster, the within sum of squares for a single cluster is the average squared distance of each point in the cluster from the cluster’s centroid. The total within sum of squares is the sum of the within sum of squares of all the clusters.</p>
<p>The total WSS will decrease as the number of clusters increases, because each cluster will be smaller and tighter. The hope is that the rate at which the WSS decreases will slow down for k beyond the optimal number of clusters.</p>
<p><strong><em>Calinski-Harabasz index</em></strong> The Calinski-Harabasz index of a clustering is the ratio of the between-cluster variance (which is essentially the variance of all the cluster centroids from the dataset’s grand centroid) to the total within-cluster variance (basically, the average WSS of the clusters in the clustering).</p>
<p>For a given dataset, the total sum of squares (TSS) is the squared distance of all the data points from the dataset’s centroid. The TSS is independent of the clustering.</p>
<p>If WSS(k) is the total WSS of a clustering with k clusters, then the between sum of squares BSS(k) of the clustering is given by BSS(k) = TSS - WSS(k). WSS(k) measures how close the points in a cluster are to each other. BSS(k) measures how far apart the clusters are from each other. A good clustering has a small WSS(k) and a large BSS(k).</p>
<p>The within-cluster variance W is given by WSS(k) / (n-k), where n is the number of points in the dataset. The between-cluster variance B is given by BSS(k) / (k-1). The within-cluster variance will decrease as k increases; the rate of decrease should slow down past the optimal k. The between-cluster variance will increase as k, but the rate of increase should slow down past the optimal k. So in theory, the ratio of B to W should be maximized at the optimal k.</p>
<p><img src="/blog/clustering-business-customers_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>It looks like the local maximum occrs at k = 6 for the CH critereon. The WSS plot may have an elbow there at k = 3. Let’s run the <code>kmeans</code> algorithm with k = 6 and examine the clusters.</p>
</div>
<div id="k-means-clustering-1" class="section level3">
<h3>K-means clustering</h3>
<p>We’ll run the algorithms with <code>k = 4</code>, 100 random starts, and 100 maximum iterations per run.</p>
<pre class="r"><code># cluster data
clusters &lt;- kmeans(p_matrix, centers = 6, nstart = 100, iter.max = 100)

# view the centers of the clusters
clusters$centers</code></pre>
<pre><code>##       profiles team_members
## 1  0.663729659   -0.4091606
## 2 -0.005778623    1.0077817
## 3 -0.556415477   -0.5601243
## 4 -0.058085908    2.3532484
## 5  2.492129136   -0.0643209
## 6  2.014109272    1.9931782</code></pre>
<p>Notice that these are scaled values that are not the original coordinates. It is still helpful to see the <em>relative</em> values for the groups. Let’s see how many users are in each group. Generally, a good clustering will be well-balanced.</p>
<pre class="r"><code># get group size
clusters$size</code></pre>
<pre><code>## [1]  811  769 4195  520  446  357</code></pre>
<p>It looks like the third cluster has a huge number of users, but that isn’t necessarily a bad thing. We can assign each user in the original dataset to a cluster and make some exploratory plots.</p>
<pre class="r"><code># assign clusters to users
users$cluster &lt;- as.factor(clusters$cluster)

# plot team members and profiles
ggplot(users, aes(x = profiles, y = team_members, color = cluster)) +
  geom_point(aes(shape = cluster), position = &quot;jitter&quot;) +
  theme_ipsum() +
  scale_x_continuous(limits = c(0, 30)) +
  scale_y_continuous(limits = c(0, 6)) +
  labs(x = &quot;Profiles&quot;, y = &quot;Team Members&quot;)</code></pre>
<p><img src="/blog/clustering-business-customers_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>

      </article>

      <ul class="pager blog-pager">
        
          <li class="previous">
            <a href="/blog/annual-ltv/" data-toggle="tooltip" data-placement="top" title="A case for annual subscriptions">&larr; Previous Post</a>
          </li>
        
        
          <li class="next">
            <a href="/blog/values_survey/" data-toggle="tooltip" data-placement="top" title="How Buffer lives its values">Next Post &rarr;</a>
          </li>
        
      </ul>

      
        
      

    </div>
  </div>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:julianwinternheimer@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://www.facebook.com/julian.winternheimer" title="Facebook">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/jwinternheimer" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/julheimer" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/jwinternheimer" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="/index.xml" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          Julian Winternheimer
          &nbsp;&bull;&nbsp;
          2018

          
            &nbsp;&bull;&nbsp;
            <a href="/">Data Analysis?</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="http://gohugo.io">Hugo v0.23</a> powered &nbsp;&bull;&nbsp; Theme by <a href="http://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a> adapted to <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha384-dq1/gEHSxPZQ7DdrM82ID4YVol9BYyU7GbWlIwnwyPzotpoc57wDw/guX8EaYGPx" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> renderMathInElement(document.body); </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe.min.js" integrity="sha256-UplRCs9v4KXVJvVY+p+RSo5Q4ilAUXh7kpjyIP5odyc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe-ui-default.min.js" integrity="sha256-PWHOlUzc96pMc8ThwRIXPn8yH4NOLu42RQ0b9SpnpFk=" crossorigin="anonymous"></script>
<script src="/js/load-photoswipe.js"></script>




  </body>
</html>

